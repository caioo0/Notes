{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2ab040",
   "metadata": {},
   "source": [
    "# 感知机\n",
    "\n",
    "\n",
    "1．感知机是根据输入实例的特征向量$x$对其进行二类分类的线性分类模型：\n",
    "\n",
    "$$\n",
    "f(x)=\\operatorname{sign}(w \\cdot x+b)\n",
    "$$\n",
    "\n",
    "感知机模型对应于输入空间（特征空间）中的分离超平面$w \\cdot x+b=0$。\n",
    "\n",
    "2．感知机学习的策略是极小化损失函数：\n",
    "\n",
    "$$\n",
    "\\min _{w, b} L(w, b)=-\\sum_{x_{i} \\in M} y_{i}\\left(w \\cdot x_{i}+b\\right)\n",
    "$$\n",
    "\n",
    "损失函数对应于误分类点到分离超平面的总距离。\n",
    "\n",
    "3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。\n",
    " \n",
    "4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数$k$满足不等式：\n",
    "\n",
    "$$\n",
    "k \\leqslant\\left(\\frac{R}{\\gamma}\\right)^{2}\n",
    "$$\n",
    "\n",
    "当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0978bff",
   "metadata": {},
   "source": [
    "###  sigmod 函数\n",
    "\n",
    "$$\n",
    "  \\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "sigmoid 函数是一个常用的逻辑函数，形状类似于字母 S。在 Python 中，我们可以使用 NumPy 库中的 exp 函数来实现它。\n",
    "\n",
    "以下是一个简单的 Python 函数，用于计算 sigmoid 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "  \n",
    "def sigmoid(x):  \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2f8a3",
   "metadata": {},
   "source": [
    "也可以使用原生语句实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  \n",
    "  \n",
    "def sigmoid(x):  \n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bffd25",
   "metadata": {},
   "source": [
    "### 二分类模型\n",
    "$f(x) = sign(w\\cdot x + b)$\n",
    "\n",
    "$\\operatorname{sign}(x)=\\left\\{\\begin{array}{ll}{+1,} & {x \\geqslant 0} \\\\ {-1,} & {x<0}\\end{array}\\right.$\n",
    "\n",
    "给定训练集：\n",
    "\n",
    "$T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}$\n",
    "\n",
    "定义感知机的损失函数 \n",
    "\n",
    "$L(w, b)=-\\sum_{x_{i} \\in M} y_{i}\\left(w \\cdot x_{i}+b\\right)$\n",
    "\n",
    "---\n",
    "#### 算法\n",
    "\n",
    "随即梯度下降法 Stochastic Gradient Descent\n",
    "\n",
    "随机抽取一个误分类点使其梯度下降。\n",
    "\n",
    "$w = w + \\eta y_{i}x_{i}$\n",
    "\n",
    "$b = b + \\eta y_{i}$\n",
    "\n",
    "当实例点被误分类，即位于分离超平面的错误侧，则调整$w$, $b$的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类\n",
    "\n",
    "\n",
    "### iris实例：\n",
    "\n",
    "[iris数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "\n",
    "\n",
    "**pandas**\n",
    "- Pandas 官网 https://pandas.pydata.org/\n",
    "- Pandas 源代码：https://github.com/pandas-dev/pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ce872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data,columns = iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc71f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = iris.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "]\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')\n",
    "plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93377901",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df.iloc[:100,[0,1,-1]]) # 通过位置选择前100行的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d21bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data[:,:-1],data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1 if i == 1 else -1 for i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2264d679",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b190d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据线性可分，二分类数据 \n",
    "# 此处为一元一次线性方程\n",
    "\n",
    "\n",
    "# 定义单层感知机\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.w = np.ones(len(data[0]) - 1, dtype=np.float32)\n",
    "        self.b = 0\n",
    "        self.l_rate = 0.01\n",
    "        # self.data = data\n",
    "\n",
    "    def sign(self, x, w, b):\n",
    "        y = np.dot(x, w) + b\n",
    "        return y\n",
    "\n",
    "    # 随机梯度下降法\n",
    "    def fit(self, X_train, y_train):\n",
    "        is_wrong = False\n",
    "        while not is_wrong:\n",
    "            wrong_count = 0\n",
    "            for d in range(len(X_train)):\n",
    "                X = X_train[d]\n",
    "                y = y_train[d]\n",
    "                if y * self.sign(X, self.w, self.b) <= 0:\n",
    "                    self.w = self.w + self.l_rate * np.dot(y, X)\n",
    "                    self.b = self.b + self.l_rate * y\n",
    "                    wrong_count += 1\n",
    "            if wrong_count == 0:\n",
    "                is_wrong = True\n",
    "        return 'Perceptron Model!'\n",
    "\n",
    "    def score(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Model()\n",
    "perceptron.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_points = np.linspace(4, 7, 10)\n",
    "y_ = -(perceptron.w[0] * x_points + perceptron.b) / perceptron.w[1]\n",
    "plt.plot(x_points, y_)\n",
    "\n",
    "plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')\n",
    "plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7053a",
   "metadata": {},
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1bec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =Perceptron(fit_intercept =True,max_iter=1000,shuffle=True)\n",
    "\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights assigned to the features.\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 截距 Constants in decision function.\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5031a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画布大小\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# 中文标题\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.title('鸢尾花线性数据示例')\n",
    "\n",
    "plt.scatter(data[:50, 0], data[:50, 1], c='b', label='Iris-setosa',)\n",
    "plt.scatter(data[50:100, 0], data[50:100, 1], c='orange', label='Iris-versicolor')\n",
    "\n",
    "# 画感知机的线\n",
    "x_ponits = np.arange(4, 8)\n",
    "y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]\n",
    "plt.plot(x_ponits, y_)\n",
    "\n",
    "# 其他部分\n",
    "plt.legend()  # 显示图例\n",
    "plt.grid(False)  # 不显示网格\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3885b1",
   "metadata": {},
   "source": [
    "**注意 !**\n",
    "\n",
    "在上图中，有一个位于左下角的蓝点没有被正确分类，这是因为 SKlearn 的 Perceptron 实例中有一个`tol`参数。\n",
    "\n",
    "`tol` 参数规定了如果本次迭代的损失和上次迭代的损失之差小于一个特定值时，停止迭代。所以我们需要设置 `tol=None` 使之可以继续迭代："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27900db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(fit_intercept=True, \n",
    "                 max_iter=1000,\n",
    "                 tol=None,\n",
    "                 shuffle=True)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# 画布大小\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# 中文标题\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.title('鸢尾花线性数据示例')\n",
    "\n",
    "plt.scatter(data[:50, 0], data[:50, 1], c='b', label='Iris-setosa',)\n",
    "plt.scatter(data[50:100, 0], data[50:100, 1], c='orange', label='Iris-versicolor')\n",
    "\n",
    "# 画感知机的线\n",
    "x_ponits = np.arange(4, 8)\n",
    "y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]\n",
    "plt.plot(x_ponits, y_)\n",
    "\n",
    "# 其他部分\n",
    "plt.legend()  # 显示图例\n",
    "plt.grid(False)  # 不显示网格\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486fbff2",
   "metadata": {},
   "source": [
    "### 使用感知机实现 mnist\n",
    "\n",
    "- mnist_loader.py\n",
    "- network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_loader.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Author: Caioo\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"通过调用torchvision中datasets模块来导入MNIST数据集中的训练集和测试集，\n",
    "    将导入的训练集通过DataLoader加载为train_loader，\n",
    "    测试集总共有10，000的样本数，分别取5，000作为验证集和测试集，对验证机和测试\n",
    "    集中样本打乱通过DataLoader加载为validation_loader和test_loader\n",
    "    \"\"\"\n",
    "    train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    indices = range(len(test_dataset))\n",
    "    indices_val = indices[:5000]\n",
    "    indices_test = indices[5000:]\n",
    "\n",
    "    sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "    sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                                    sampler=sampler_val)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                              sampler=sampler_test)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## network.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"通过pytorch中神经网络的模块和函数来构建对MNIST数据集网络的构建、\n",
    "训练、验证、和测试，整个过程使用了三层的神经元的网络来建立网络；最后\n",
    "测试集中的正确率有94.36%左右，通过增加网络层数，调整参数，迭代次数，\n",
    "损失函数等等都能对提高正确率起一定效果\n",
    "\n",
    "Author: Caioo0\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import mnist_loader\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"这里以[784 30 10]三层神经网络为例\n",
    "    \"\"\"\n",
    "    def __init__(self, sizes):\n",
    "        super(Network, self).__init__()\n",
    "        self.sizes = sizes\n",
    "        self.layer1 = nn.Linear(sizes[0], sizes[1])\n",
    "        self.layer2 = nn.Linear(sizes[1], sizes[2])\n",
    "\n",
    "    def forward(self, a):\n",
    "        a = a.view(-1, self.sizes[0])  # view函数将输入Tensor转换成（64, 784）\n",
    "        a = self.layer1(a)\n",
    "        a = self.layer2(a)\n",
    "        a = torch.log_softmax(a, dim=1)\n",
    "        return a\n",
    "\n",
    "\n",
    "def rightness(output, target):\n",
    "    \"\"\"输入网络的输出Tensor和目标Tensor，\n",
    "    比较网络的输出Tensor和目标Tensor中对应相等的结果，\n",
    "    返回比较结果中匹配正确的个数和整个输出或者目标Tensor\n",
    "    的长度\n",
    "    \"\"\"\n",
    "    rights = 0\n",
    "    for index in range(len(target.data)):\n",
    "        if torch.argmax(output[index]) == target.data[index]:\n",
    "            rights += 1\n",
    "    return rights, len(target.data)\n",
    "\n",
    "\n",
    "def train_model(train_loader, epochs, eta):\n",
    "    \"\"\"本函数的功能是训练模型，使用交叉熵的损失函数，和\n",
    "    随机梯度下降的优化算法，学习率为0.001，动量为0.9\n",
    "    开始训练循环\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=eta, momentum=0.9)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_rights = []  # 记录每次迭代正确的结果和总样本\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            net.train()\n",
    "\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            optimizer.zero_grad()  # 清空梯度\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 一步随机梯度下降算法\n",
    "            right = rightness(output, target)  # 计算一批次准确率中（正确样例数， 总样本数）\n",
    "            train_rights.append(right)\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                validation_model(validation_loader)\n",
    "\n",
    "        # 求得整个训练样本中正确的样例总数， 和总样本数，可以通过两者得到训练的正确率\n",
    "        train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "        print(\"Epoch {0}: {1}/{2}\".format(epoch, train_r[0], train_r[1]))\n",
    "\n",
    "\n",
    "def validation_model(validation_loader):\n",
    "    \"\"\"验证模型\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    val_rights = []\n",
    "\n",
    "    for data, target in validation_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = net(data)\n",
    "        right = rightness(output, target)\n",
    "        val_rights.append(right)\n",
    "\n",
    "    val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "    print(\"验证集的正确率为{:.2f}%\".format(100.0 * val_r[0] / val_r[1]))\n",
    "\n",
    "\n",
    "def test_model(test_loader):\n",
    "    \"\"\"测试模型\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    vals = []\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = net(data)\n",
    "        val = rightness(output, target)\n",
    "        vals.append(val)\n",
    "\n",
    "    rights = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n",
    "    print(\"测试集的正确率为{:.2f}%\".format(100.0 * rights[0] / rights[1]))\n",
    "\n",
    "\n",
    "train_loader, validation_loader, test_loader = mnist_loader.load_data()\n",
    "net = Network([784, 30, 10])\n",
    "train_model(train_loader, 20, 0.001)\n",
    "test_model(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e63d1f",
   "metadata": {},
   "source": [
    "### 练习题\n",
    "\n",
    "#### 问题1  假设把一个感知机网络中的所有权重和偏置乘以一个正的常数c ，请证明该网络的行为不会改变。\n",
    "\n",
    "**解答：**\n",
    "\n",
    "为了证明把一个感知机网络中的所有权重和偏置乘以一个正的常数c不会改变该网络的行为，我们需要知道感知机的基本工作原理。感知机是一种二元线性分类器，它的基本形式是：\n",
    "$$\n",
    "g(x) = sign(w·x + b)\n",
    "$$\n",
    "其中，w和b是权重和偏置，x是输入，sign是符号函数，它将w·x + b的值映射到+1或-1两个类别之一。\n",
    "现在，如果我们将所有的权重和偏置乘以c，得到的新的感知机为：\n",
    "$$\n",
    "g_c(x) = sign(c·w·x + c·b)\n",
    "$$\n",
    "显然，`c·w·x + c·b`仍然是一个线性函数，并且它的斜率和原来的斜率相同（因为c是常数），因此，它仍然是一个线性分类器。所以，该网络的行为不会改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74fc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "files=zipfile.ZipFile('./Perceptron.zip','r')  #第一个参数：解压的文件\n",
    "files.extractall('./Perceptron') #解压的目标存放文件夹位置\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28194c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
