# 美团机器学习实践之1 问题建模

**机器学习的流程：**

问题建模 - > 特征工程 -> 模型选择 -> 模型融合

![image-20231219081054995](.\img\image-20231219081054995.png)

## 1.1 评估指标

> 反映模型效果，评估公式是关于预测结果f(x)和真实标注Y 之间比较的函数

$$
score = metric(f(x),Y)

$$

根据任务类型分类： **分类指标 、 回归指标、聚类指标和排序指标。**

### 1.1.1 分类指标

#### 1）精准率和召回率

> 多用于二分类问题，可结合混淆矩阵介绍

![image-20231219081546396](.\img\image-20231219081546396.png)

$$
样本总数 = TP + FP + FN + TN

$$

$$
精准率（P） = \frac{TP}{TP+FP} \\
召回率（R） = \frac{TP}{TP+FN}

$$

公式理解：

- 精准率 = 正确预测为正例 除以 所有**预测样本**为正样本  （二分类）
- 召回率 = 正确预测为正例  除以  所有**真实样本**为正样本

理想情况下，精确率和召回率越高越好，事实某些情况是矛盾的，

![image-20231219083423367](.\img\image-20231219083423367.png)

可以通过 $F_1$ 衡量，$F_1$ 是 精确率和召回率的调和平均值：

$$
\frac{2}{F_1} = \frac{1}{P}+ \frac{1}{R}  \\
F_a = \frac{(1+a^2).P.R}{a^2.P+R}  \tag{1}

$$

再介绍可用于多分类准确率和错误率 ：

$$
准确率（accuracy） = \frac{TP+TN}{TP+FP+FN+TN} \\
错误率（error rate）= \frac{TP+FN}{TP+FP+FN+TN}

$$

$$
准确率(accuracy) = \frac{1}{n}\sum^n_{i=1}I(f(x_i)= y_i)

$$

#### 2) ROC 与 AUC

P-R曲线是从精准率（查准率）和召回率（查全率）的角度去衡量学习模型的泛化性能，

ROC曲线则是从更一般的情况下去衡量学习模型的泛化性能，若没有任何先验条件的限制情况下，推荐用ROC曲线去衡量模型的泛化性能。

$$
TPR(真阳性) = \frac{TP}{TP+FN} \\
FPR(假阳性) = \frac{FP}{FP+TN}

$$

```python
from sklearn.metrics import roc_curve, auc
import numpy as np
##y_test相当于真实值，注意，roc曲线仅适用于二分类问题，多分类问题应先转化为二分类
y_test = np.array([1,1,0,1,1,1,0,0,1,0,1,0,1,0,0,0,1,0,1,0])
#y_score 根据x_test预测出的y_pre,根据出现的概率大小进行排列
y_score = np.array([0.9,0.8,0.7,0.6,0.55,0.54,0.53,0.52,0.51,0.505,0.4,0.39,0.38,0.37,0.36,0.35,0.34,0.33,0.3,0.1])
##
fpr,tpr,thre = roc_curve(y_test,y_score)
##计算auc的值，就是roc曲线下的面积
auc = auc(fpr,tpr)
##画图
plt.plot(fpr,tpr,color = 'darkred',label = 'roc area:(%0.2f)'%auc)
plt.plot([0,1],[0,1],linestyle = '--')
plt.xlim([0,1])
plt.ylim([0,1])
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.title('roc_curve')
plt.legend(loc = 'lower right')
```

```python
from sklearn.preprocessing import LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle
import pandas as pd
from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
 
data = pd.read_csv('iris.csv',header = None)
##将第四列的无序非数值型数据转为数值型数据
y = data[[4]]
class_le = LabelEncoder()
y = class_le.fit_transform(y.values.ravel())
 
##对数据进行改造，成为二分类问题
X= data[[0,1,2,3]][y != 2]
y = y[y!=2]
 
# Add noisy features to make the problem harder
random_state = np.random.RandomState(0)
n_samples, n_features = X.shape
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
 
# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,random_state=0)
 
## Learn to predict each class against the other
classifier = svm.SVC(kernel='linear', probability=True,random_state=random_state)
 
##由decision_function函数得到y_score
y_score = classifier.fit(X_train,y_train).decision_function(X_test)
 
fpr,tpr,thre = roc_curve( y_test,y_score )
#
roc_auc = auc(fpr,tpr)
#
plt.figure()
lw = 2
plt.figure(figsize = (9,8))
plt.plot(fpr,tpr,color = 'darkorange',lw = lw,
         label = 'ROC curve (area = %0.2f)' %roc_auc)
plt.plot( [0,1],[0,1],color = 'navy' ,lw = lw,
         linestyle = '--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
```
