{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e496b4a",
   "metadata": {},
   "source": [
    "# 第8章 音频扩散模型\n",
    "---\n",
    "## 8.1 实战：音频扩散模型\n",
    "\n",
    "### 8.1.1 设置与导入\n",
    "\n",
    "首先安装需要用到的库并配置环境，代码如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023f51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets diffusers torchaudio accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4aa2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "from diffusers import DiffusionPipeline\n",
    "from torchaudio import transforms as AT\n",
    "from torchvision import transforms as IT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbd9d7",
   "metadata": {},
   "source": [
    "### 8.1.2 从预训练的音频扩散模型管线中进行采样\n",
    "\n",
    "加载一个预训练的音频扩散模型管线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载一个预训练的音频扩散模型管线\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mypipe = \"teticio/audio\u0002diffusion-instrumental-hiphop- 256\"\n",
    "pipe   = DiffusionPipeline.from_pretrained(mypipe).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在管线中采样一次并将采样结果显示出来\n",
    "output = pipe()\n",
    "display(output.images[0])\n",
    "display(Audio(output.audio[0],\n",
    "rate = pipe.mel.get_sample_rate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859dbd9",
   "metadata": {},
   "source": [
    "在上述代码中，rate参数定义了音频的采样率。此外你可能还会注意到管线返回了其他一些内容。\n",
    "\n",
    "首先是数据数组，代表生成的音频："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音频序列\n",
    "output.audios[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ffc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出的图像（频谱）\n",
    "output.images[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e6c7c",
   "metadata": {},
   "source": [
    "注意：音频并非由扩散模型直接生成\n",
    "\n",
    "扩展：[梅 尔 频 谱 (Mel spectrogram)](https://www.rtcdeveloper.cn/cn/community/blog/21571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86deac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.1.3 从音频到频谱的转换\n",
    "spec_transform = AT.Spectrogram(power=2)\n",
    "spectrogram = spec_transform(torch.tensor(output.audios[0]))\n",
    "print(spectrogram.min(),spectrogram.max())\n",
    "log_spectrogram = spectrogram.log()\n",
    "lt.imshow(log_spectrogram[0],cmap = 'gray');\n",
    "tensor(0.) tensor(6.0842)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加mel频谱\n",
    "a = pipe.mel.image_to_audio(output.images[0])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3333dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip.mel.load_audio(raw_audio=a)\n",
    "im = pipe.mel.audio_slice_to_image(0)\n",
    "im "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_pipeline = pipe.mel.get_sample_rate()\n",
    "sample_rate_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c21b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(output.audios[0],rate=44100)) # 播放速度被加倍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007afe3",
   "metadata": {},
   "source": [
    "### 8.1.4 微调管线\n",
    "\n",
    "尝试一个新得示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('lewtun/music_genres', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c17cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in list(set(dataset['genre'])):\n",
    " print(g, sum(x==g for x in dataset['genre']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd84071",
   "metadata": {},
   "source": [
    "该数据集已将音频存储为数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d91f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_array = dataset[0]['audio']['array']\n",
    "sample_rate_dataset = dataset[0]['audio']['sampling_rate']\n",
    "print('Audio array shape:', audio_array.shape)\n",
    "print('Sample rate:', sample_rate_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a24c2",
   "metadata": {},
   "source": [
    "使用pipe.mel 将其自动切片为更短的片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_array = dataset[0]['audio']['array']\n",
    "sample_rate_dataset = dataset[0]['audio']['sampling_rate']\n",
    "print('Audio array shape:', audio_array.shape)\n",
    "print('Sample rate:', sample_rate_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51301b0",
   "metadata": {},
   "source": [
    "调整采样率，因为该数据集中的数据在每一秒都拥有两倍的数据点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c10c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_dataset = dataset[0]['audio']['sampling_rate']\n",
    "sample_rate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf849ab5",
   "metadata": {},
   "source": [
    "使用torchaudio transforms（导入为AT）进行音频的重采样，并使用管线的mel功能将音频转换为频谱图像，然后使用\n",
    "torchvision transforms（导入为IT）将频谱图像转换为频谱张量。以下代码中的to_image()函数可以将音频片段转换为频谱张量，供训\n",
    "练使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42182b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = AT.Resample(sample_rate_dataset,\n",
    "sample_rate_pipeline,\n",
    " dtype=torch.float32)\n",
    "to_t = IT.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(audio_array):\n",
    "     audio_tensor = torch.tensor(audio_array).to(torch.float32)\n",
    "     audio_tensor = resampler(audio_tensor)\n",
    "     pipe.mel.load_audio(raw_audio=np.array(audio_tensor))\n",
    "     num_slices = pipe.mel.get_number_of_slices()\n",
    "     slice_idx = random.randint(0, num_slices-1) # 每次随机取一张（除了最后那张）\n",
    "     im = pipe.mel.audio_slice_to_image(slice_idx)\n",
    "     return im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651d102",
   "metadata": {},
   "source": [
    "将每个音频转换为频谱图像，然后将它们的张量堆叠起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a926b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    # 将图像转变为张量，再缩放到(-1, 1)区间，再变成数组\n",
    "    audio_ims = [to_t(to_image(x['audio']['array']))*2-1 for x in examples]\n",
    "    return torch.stack(audio_ims)\n",
    "\n",
    "# 创建一个只包含Chiptune/Glitch风格的音乐\n",
    "batch_size=4\n",
    "# 设置训练风格\n",
    "chosen_genre = 'Electronic'\n",
    "indexes = [i for i, g in enumerate(dataset['genre']) if g == chosen_genre]\n",
    "filtered_dataset = dataset.select(indexes)\n",
    "filtered_dataset = filtered_dataset.select(range(100))\n",
    "dl = torch.utils.data.DataLoader(filtered_dataset.shuffle(), batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "batch = next(iter(dl))\n",
    "print(batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62074743",
   "metadata": {},
   "source": [
    "### 8.1.5 训练循环\n",
    "\n",
    "下面的训练循环通过使用几个周期微调管线的UNet网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "lr = 1e-4\n",
    "\n",
    "pipe.unet.train()\n",
    "pipe.scheduler.set_timesteps(1000)\n",
    "optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in tqdm(enumerate(dl), total=len(dl)):\n",
    "        # 输入图片\n",
    "        clean_images = batch.to(device)\n",
    "        bs = clean_images.shape[0]\n",
    "        # 为每一张图片设置一个随机的时间步\n",
    "        timesteps = torch.randint(\n",
    "            0, pipe.scheduler.config.num_train_timesteps, (bs,), device=clean_images.device\n",
    "        ).long()\n",
    "        \n",
    "        # 添加噪声\n",
    "        noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
    "        noisy_images = pipe.scheduler.add_noise(clean_images, noise, timesteps)\n",
    "        \n",
    "        # 得到噪声预测\n",
    "        noise_pred = pipe.unet(noisy_images, timesteps, return_dict=False)[0]\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        loss.backward(loss)\n",
    "        \n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 装载之前训练好的频谱样本，如图8-6所示\n",
    "output = pipe()\n",
    "display(output.images[0])\n",
    "display(Audio(output.audios[0], rate=22050))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff679559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入一个不同形状的起点噪声张量，可以得到一个更长的频谱样本\n",
    "noise = torch.randn(1, 1, pipe.unet.sample_size, pipe.unet.sample_size*4).to(device)\n",
    "output = pipe(noise=noise)\n",
    "display(output.images[0])\n",
    "display(Audio(output.audios[0], rate=22050))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b2372",
   "metadata": {},
   "source": [
    "这个输出可能不是最佳结果，可以尝试调整学习率和迭代周期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9159fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
