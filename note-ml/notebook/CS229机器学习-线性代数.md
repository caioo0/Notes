# CS229 机器学习课程复习材料 - 线性代数



> 本文是斯坦福大学CS229机器学习课程的基础材料，[原始文件下载](http://cs229.stanford.edu/summer2019/cs229-linalg.pdf) 原作者：Zico Kolter，修改：Chuong Do， Tengyu Ma
>
> 翻译：[黄海广](https://github.com/fengdu78)
>备注：请关注[github](https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math)的更新，线性代数和概率论已经更新完毕。

##  线性代数复习和参考

### 1. 基础概念和符号

线性代数提供了一种紧凑地表示和操作线性方程组的方法。例如，以下方程组：
$$
4x_1 − 5x_2 = −13
$$

$$
-2x_1 + 3x_2 = 9
$$

这是两个方程和两个变量，正如你从高中代数中所知，你可以找到$x_1$和 $x_2$ 的唯一解（除非方程以某种方式退化，例如，如果第二个方程是第一个的倍数，但在上面的情况下，实际上只有一个唯一解）。在矩阵表示法中，我们可以更紧凑地表达：
$$
Ax=b
$$

$$
\text {with} A = \left[\begin{array}{cc} {4} & {-5} \\ {-2} & {3}\end{array}\right],b=\left[\begin{array}{c}{-13} \\ {9} \end{array}\right] 
$$

我们可以看到，这种形式的线性方程有许多优点（比如明显地节省空间）。

#### 1.1 基本符号

我们使用以下符号：

- $ A \in \mathbb{R}^{m \times n}$ ,表示 $A$ 为由实数组成具有m行和n列的矩阵。
- $x \in \mathbb{R}^{n}$,表示具有 $n$ 个元素的向量。通常，向量 $x$表示列向量：即，具有 $n$行和1列的矩阵。如果想要明确表示行向量：具有 $1$行和$n$列的矩阵 - 我们通常写$x^T$(这里$x^Tx$的转置)。
- $x_i$表示向量$x$的第$i$个元素。

$$
x = \left[\begin{array}{c}{x_1} \\ {x_2} \\ {\vdots} \\ 
     {x_n} \end{array}\right]
$$

- 我们使用符号$a_{ij}$ (或$A_{ij},A_{i,j}$等)来表示第$ i $ 行和第 $j$ 列的元素：

$$
A=\left[\begin{array}{cccc}{a_{11}} & {a_{12}} & {\cdots} & {a_{1 n}} \\ {a_{21}} & {a_{22}} & {\cdots} & {a_{2 n}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {a_{m 1}} & {a_{m 2}} & {\cdots} & {a_{m n}}\end{array}\right]
$$

- 我们用$a^j$ 或者 $ A_{:,j}$表示矩阵$A$的第$j$列

$$
A = \left[\begin{array}{llll}{|} & {|} & {} & {|} \\
{a^1} & {a^2} & {\cdots} & {a^n} \\
{|} & {|} & {} & {|}\end{array}\right ]
$$

- 我们用$a_i^{T}$或者$A_{i,:}$ 表示矩阵$A$的第$i$行：

$$
A = \left[\begin{array}{c}{-a_{1}^{T}-} \\ {-a_{2}^{T}-}\\{\vdots}\\{-a_{m}^{T}-}\end{array}\right]
$$

- 在许多情况下，将矩阵视为列向量或行向量的集合非常重要且方便。 通常，在向量而不是标量上操作在数学上（和概念上）更清晰。只要明确定义了符号，用于矩阵的列或行的表示方式并没有通用约定。

### 2. 矩阵乘法

两个矩阵相乘，其中$A\in\mathbb{R}^{m \times n}$ and  $B\in\mathbb{R}^{n \times p}$ ,则：
$$
C = AB \in \mathbb{R}^{m \times p}
$$
其中：
$$
C_{ij} = \sum_{k-1}^nA_{ik}B_{kj}
$$
请注意，为了使矩阵乘积存在，A中的列数必须等于B中的行数。有很多方法可以查看矩阵乘法，我们将从检查一些特殊情况开始。

#### 2.1 向量-向量乘法

给定两个向量$x,y \in \mathbb{R}^n,x^Ty$通常称为 **向量内积**或**点积**，结果是个**实数**。
$$
x^{T}y \in \mathbb{R} = \left[\begin{array}{llll}{x_1} & {x_2} & {\cdots} & {x_n}\end{array}\right]\left[\begin{array}{c}{y_{1}} \\ {y_{2}} \\ {\vdots} \\ {y_{n}}\end{array}\right]=\sum_{i=1}^{n} x_{i} y_{i}
$$
注意：$x^Ty=y^Tx$始终成立。

给定向量$x\in \mathbb{R}^m,y \in \mathbb {R}^n$(他们的维度是否相同都没关系)，$$xy^T \in \mathbb{R}^{m \times n} $$ 叫做**向量外积**，当$(xy^T)_{ij} = x_iy_j$的时候，它是一个矩阵。
$$
x y^{T} \in \mathbb{R}^{m \times n}=\left[\begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{m}}\end{array}\right]\left[\begin{array}{llll}{y_{1}} & {y_{2}} & {\cdots} & {y_{n}}\end{array}\right]=\left[\begin{array}{cccc}{x_{1} y_{1}} & {x_{1} y_{2}} & {\cdots} & {x_{1} y_{n}} \\ {x_{2} y_{1}} & {x_{2} y_{2}} & {\cdots} & {x_{2} y_{n}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {x_{m} y_{1}} & {x_{m} y_{2}} & {\cdots} & {x_{m} y_{n}}\end{array}\right]
$$
举一个外积如何使用的一个例子：让$1\in R^{n}$表示一个$n$维向量，其元素都等于1，此外，考虑矩阵$A \in R^{m \times n}$，其列全部等于某个向量 $x \in R^{m}$。 我们可以使用外积紧凑地表示矩阵 $A$:
$$
A=\left[\begin{array}{llll}{ |} & { |} & {} & { |} \\ {x} & {x} & {\cdots} & {x} \\ { |} & { |} & {} & { |}\end{array}\right]=\left[\begin{array}{cccc}{x_{1}} & {x_{1}} & {\cdots} & {x_{1}} \\ {x_{2}} & {x_{2}} & {\cdots} & {x_{2}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {x_{m}} & {x_{m}} & {\cdots} & {x_{m}}\end{array}\right]=\left[\begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{m}}\end{array}\right]\left[\begin{array}{lll}{1} & {1} & {\cdots} & {1}\end{array}\right]=x \mathbf{1}^{T}
$$

#### 2.2 矩阵-向量乘法

#### 2.3 矩阵-矩阵乘法