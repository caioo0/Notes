# 第二讲 马尔科夫决策过程
---

> 马尔科夫决策过程（Markov decision process, MDP）是对完全可观测的环境进行描述的，也就是说观测到的状态内容完整地决定了决策的需要的特征。几乎所有的强化学习问题都可以转化为MDP。

## 马尔科夫过程(Markov Process)

- **马尔科夫性(Markov Property):** 某一状态信息包含了所有相关的历史，只要当前状态可知，所有的历史信息都不再需要，当前状态就可以决定未来，则认为该状态具有马尔科夫性。

- **马尔科夫过程(Markov Process):**

**马尔科夫过程**又叫马尔科夫链(Markov Chain)，它是一个无记忆的随机过程，可以用一个元组<S,P>表示，其中S是有限数量的状态集，P是状态转移概率矩阵。

**马尔科夫奖励过程(Markov Reward Process)**

马尔科夫奖励过程在马尔科夫过程的基础上增加了奖励R和衰减系数γ：<S,P,R,γ>。R是一个奖励函数。S状态下的奖励是某一时刻(t)处在状态s下在下一个时刻(t+1)能获得的奖励期望：

$$
 R_{s} = E[R_{t+1} | S_{t} = s]
$$

